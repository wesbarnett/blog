<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Classification Decision Trees &amp; Entropy | Wes Barnett, PhD</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Classification Decision Trees &amp; Entropy" />
<meta name="author" content="Wes Barnett" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="An introduction to classification decision trees, specifically looking at how trees make splits based on entropy" />
<meta property="og:description" content="An introduction to classification decision trees, specifically looking at how trees make splits based on entropy" />
<link rel="canonical" href="https://barnett.science/machinelearning/2019/05/14/decision-trees.html" />
<meta property="og:url" content="https://barnett.science/machinelearning/2019/05/14/decision-trees.html" />
<meta property="og:site_name" content="Wes Barnett, PhD" />
<meta property="og:image" content="https://barnett.science/images/tree.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-05-14T00:00:00-05:00" />
<script type="application/ld+json">
{"url":"https://barnett.science/machinelearning/2019/05/14/decision-trees.html","@type":"BlogPosting","headline":"Classification Decision Trees &amp; Entropy","dateModified":"2019-05-14T00:00:00-05:00","datePublished":"2019-05-14T00:00:00-05:00","image":"https://barnett.science/images/tree.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://barnett.science/machinelearning/2019/05/14/decision-trees.html"},"author":{"@type":"Person","name":"Wes Barnett"},"description":"An introduction to classification decision trees, specifically looking at how trees make splits based on entropy","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://barnett.science/feed.xml" title="Wes Barnett, PhD" /><link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Wes Barnett, PhD</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Me</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Classification Decision Trees &amp; Entropy</h1><p class="page-description">An introduction to classification decision trees, specifically looking at how trees make splits based on entropy</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2019-05-14T00:00:00-05:00" itemprop="datePublished">
        May 14, 2019
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Wes Barnett</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      14 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#machinelearning">machinelearning</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/wesbarnett/blog/tree/master/_notebooks/2019-05-14-decision-trees.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/wesbarnett/blog/master?filepath=_notebooks%2F2019-05-14-decision-trees.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/wesbarnett/blog/blob/master/_notebooks/2019-05-14-decision-trees.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#Fitting">Fitting </a></li>
<li class="toc-entry toc-h2"><a href="#Inference">Inference </a></li>
<li class="toc-entry toc-h2"><a href="#Pruning">Pruning </a></li>
<li class="toc-entry toc-h2"><a href="#Information-gain-&-splits">Information gain &amp; splits </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Plotting-entropy-in-the-binary-class-case">Plotting entropy in the binary class case </a></li>
<li class="toc-entry toc-h3"><a href="#Finding-the-best-split-through-iteration">Finding the best split through iteration </a></li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2019-05-14-decision-trees.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this notebook I walk through how a classification decision tree is fit, how inference is performed, how to reduce overfitting, how splits are determined. This is based on a notebook I created while I was fellow at Insight Data Science when studying for interviews.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">graphviz</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">tree</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>scikit-learn now comes with a way to plot trees, but I prefer using <code>graphviz</code> so here is a quick function to plot a tree, which we monkey-patch into the <code>DecisionTreeClassifier</code> and <code>DecisionTreeRegressor</code> classes.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">display_tree</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">dot_data</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">export_graphviz</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">out_file</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">filled</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">rounded</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">special_characters</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">graph</span> <span class="o">=</span> <span class="n">graphviz</span><span class="o">.</span><span class="n">Source</span><span class="p">(</span><span class="n">dot_data</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">graph</span>

<span class="n">DecisionTreeClassifier</span><span class="o">.</span><span class="n">plot</span> <span class="o">=</span> <span class="n">display_tree</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We'll use the Iris dataset as a quick way to discuss classification trees. To learn more about this dataset use <code>help(load_iris)</code>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Fitting">
<a class="anchor" href="#Fitting" aria-hidden="true"><span class="octicon octicon-link"></span></a>Fitting<a class="anchor-link" href="#Fitting"> </a>
</h2>
<p>Decision trees search over all possible ways to split up features and find the split that is most informative about the target variable. The parent node splits into two child nodes based on this split. From there the children also split in the same manner until all leaves are pure, unless another stopping condition is specified. A leaf is a node that has no children. A pure leaf is a leaf with only one class of items in it.</p>
<p>Classifications trees split using the GINI impurity which is defined as:</p>
<p>$I_{G}(p) = \sum_{i=1}^{J}p_{i}(1-p_{i})$</p>
<p>Here $p_{i}$ is the probability of an item with label $i$ being chosen and $1 - p_{i}$ is the probability of a mistake in categorizing that item. $J$ is the number of classes. Gini reaches zero when all cases in the node fall into a single target category.</p>
<p>Alternatively, one can use information gain to decide where to split, where information gain is defined as the difference in entropy of the parent and the weighted sum of the entropies of the children. Entropy is defined as:</p>
<p>$H(p) = -\sum_{i=1}^{J}p_{i}\log_{2}(p_{i})$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's train a decision tree:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">clf</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">criterion</span><span class="o">=</span><span class="s2">"entropy"</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">clf</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_svg output_subarea output_execute_result">
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
&lt;!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"&gt;
<!-- Generated by graphviz version 2.44.0 (0)
 -->
<!-- Title: Tree Pages: 1 -->
<svg width="521pt" height="461pt" viewbox="0.00 0.00 521.00 461.00" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 457)">
<title>Tree</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-457 517,-457 517,4 -4,4"></polygon>
<!-- 0 -->
<g id="node1" class="node">
<title>0</title>
<path fill="#f8f4fe" stroke="black" d="M240.5,-453C240.5,-453 132.5,-453 132.5,-453 126.5,-453 120.5,-447 120.5,-441 120.5,-441 120.5,-401 120.5,-401 120.5,-395 126.5,-389 132.5,-389 132.5,-389 240.5,-389 240.5,-389 246.5,-389 252.5,-395 252.5,-401 252.5,-401 252.5,-441 252.5,-441 252.5,-447 246.5,-453 240.5,-453"></path>
<text text-anchor="start" x="157" y="-438.8" font-family="Helvetica,sans-Serif" font-size="14.00">X</text>
<text text-anchor="start" x="167" y="-438.8" font-family="Helvetica,sans-Serif" baseline-shift="sub" font-size="14.00">2</text>
<text text-anchor="start" x="174" y="-438.8" font-family="Helvetica,sans-Serif" font-size="14.00"> ≤ 2.35</text>
<text text-anchor="start" x="139" y="-424.8" font-family="Helvetica,sans-Serif" font-size="14.00">entropy = 1.581</text>
<text text-anchor="start" x="141.5" y="-410.8" font-family="Helvetica,sans-Serif" font-size="14.00">samples = 112</text>
<text text-anchor="start" x="128.5" y="-396.8" font-family="Helvetica,sans-Serif" font-size="14.00">value = [37, 34, 41]</text>
</g>
<!-- 1 -->
<g id="node2" class="node">
<title>1</title>
<path fill="#e58139" stroke="black" d="M164,-347.5C164,-347.5 71,-347.5 71,-347.5 65,-347.5 59,-341.5 59,-335.5 59,-335.5 59,-306.5 59,-306.5 59,-300.5 65,-294.5 71,-294.5 71,-294.5 164,-294.5 164,-294.5 170,-294.5 176,-300.5 176,-306.5 176,-306.5 176,-335.5 176,-335.5 176,-341.5 170,-347.5 164,-347.5"></path>
<text text-anchor="start" x="77.5" y="-332.3" font-family="Helvetica,sans-Serif" font-size="14.00">entropy = 0.0</text>
<text text-anchor="start" x="76.5" y="-317.3" font-family="Helvetica,sans-Serif" font-size="14.00">samples = 37</text>
<text text-anchor="start" x="67" y="-302.3" font-family="Helvetica,sans-Serif" font-size="14.00">value = [37, 0, 0]</text>
</g>
<!-- 0&#45;&gt;1 -->
<g id="edge1" class="edge">
<title>0-&gt;1</title>
<path fill="none" stroke="black" d="M164.67,-388.99C157.25,-378.46 148.93,-366.64 141.37,-355.9"></path>
<polygon fill="black" stroke="black" points="144.11,-353.72 135.49,-347.56 138.39,-357.75 144.11,-353.72"></polygon>
<text text-anchor="middle" x="131.22" y="-368.49" font-family="Helvetica,sans-Serif" font-size="14.00">True</text>
</g>
<!-- 2 -->
<g id="node3" class="node">
<title>2</title>
<path fill="#e9ddfb" stroke="black" d="M307,-353C307,-353 206,-353 206,-353 200,-353 194,-347 194,-341 194,-341 194,-301 194,-301 194,-295 200,-289 206,-289 206,-289 307,-289 307,-289 313,-289 319,-295 319,-301 319,-301 319,-341 319,-341 319,-347 313,-353 307,-353"></path>
<text text-anchor="start" x="227" y="-338.8" font-family="Helvetica,sans-Serif" font-size="14.00">X</text>
<text text-anchor="start" x="237" y="-338.8" font-family="Helvetica,sans-Serif" baseline-shift="sub" font-size="14.00">2</text>
<text text-anchor="start" x="244" y="-338.8" font-family="Helvetica,sans-Serif" font-size="14.00"> ≤ 4.95</text>
<text text-anchor="start" x="209" y="-324.8" font-family="Helvetica,sans-Serif" font-size="14.00">entropy = 0.994</text>
<text text-anchor="start" x="215.5" y="-310.8" font-family="Helvetica,sans-Serif" font-size="14.00">samples = 75</text>
<text text-anchor="start" x="202" y="-296.8" font-family="Helvetica,sans-Serif" font-size="14.00">value = [0, 34, 41]</text>
</g>
<!-- 0&#45;&gt;2 -->
<g id="edge2" class="edge">
<title>0-&gt;2</title>
<path fill="none" stroke="black" d="M208.65,-388.99C214.9,-380.23 221.8,-370.58 228.35,-361.4"></path>
<polygon fill="black" stroke="black" points="231.29,-363.31 234.26,-353.14 225.59,-359.25 231.29,-363.31"></polygon>
<text text-anchor="middle" x="238.37" y="-374.1" font-family="Helvetica,sans-Serif" font-size="14.00">False</text>
</g>
<!-- 3 -->
<g id="node4" class="node">
<title>3</title>
<path fill="#4be78c" stroke="black" d="M235,-253C235,-253 142,-253 142,-253 136,-253 130,-247 130,-241 130,-241 130,-201 130,-201 130,-195 136,-189 142,-189 142,-189 235,-189 235,-189 241,-189 247,-195 247,-201 247,-201 247,-241 247,-241 247,-247 241,-253 235,-253"></path>
<text text-anchor="start" x="159" y="-238.8" font-family="Helvetica,sans-Serif" font-size="14.00">X</text>
<text text-anchor="start" x="169" y="-238.8" font-family="Helvetica,sans-Serif" baseline-shift="sub" font-size="14.00">3</text>
<text text-anchor="start" x="176" y="-238.8" font-family="Helvetica,sans-Serif" font-size="14.00"> ≤ 1.65</text>
<text text-anchor="start" x="141" y="-224.8" font-family="Helvetica,sans-Serif" font-size="14.00">entropy = 0.414</text>
<text text-anchor="start" x="147.5" y="-210.8" font-family="Helvetica,sans-Serif" font-size="14.00">samples = 36</text>
<text text-anchor="start" x="138" y="-196.8" font-family="Helvetica,sans-Serif" font-size="14.00">value = [0, 33, 3]</text>
</g>
<!-- 2&#45;&gt;3 -->
<g id="edge3" class="edge">
<title>2-&gt;3</title>
<path fill="none" stroke="black" d="M234.98,-288.99C228.91,-280.23 222.21,-270.58 215.84,-261.4"></path>
<polygon fill="black" stroke="black" points="218.69,-259.36 210.11,-253.14 212.93,-263.35 218.69,-259.36"></polygon>
</g>
<!-- 8 -->
<g id="node9" class="node">
<title>8</title>
<path fill="#843ee6" stroke="black" d="M370,-253C370,-253 277,-253 277,-253 271,-253 265,-247 265,-241 265,-241 265,-201 265,-201 265,-195 271,-189 277,-189 277,-189 370,-189 370,-189 376,-189 382,-195 382,-201 382,-201 382,-241 382,-241 382,-247 376,-253 370,-253"></path>
<text text-anchor="start" x="294" y="-238.8" font-family="Helvetica,sans-Serif" font-size="14.00">X</text>
<text text-anchor="start" x="304" y="-238.8" font-family="Helvetica,sans-Serif" baseline-shift="sub" font-size="14.00">3</text>
<text text-anchor="start" x="311" y="-238.8" font-family="Helvetica,sans-Serif" font-size="14.00"> ≤ 1.75</text>
<text text-anchor="start" x="276" y="-224.8" font-family="Helvetica,sans-Serif" font-size="14.00">entropy = 0.172</text>
<text text-anchor="start" x="282.5" y="-210.8" font-family="Helvetica,sans-Serif" font-size="14.00">samples = 39</text>
<text text-anchor="start" x="273" y="-196.8" font-family="Helvetica,sans-Serif" font-size="14.00">value = [0, 1, 38]</text>
</g>
<!-- 2&#45;&gt;8 -->
<g id="edge8" class="edge">
<title>2-&gt;8</title>
<path fill="none" stroke="black" d="M277.7,-288.99C283.69,-280.23 290.28,-270.58 296.56,-261.4"></path>
<polygon fill="black" stroke="black" points="299.45,-263.37 302.21,-253.14 293.68,-259.42 299.45,-263.37"></polygon>
</g>
<!-- 4 -->
<g id="node5" class="node">
<title>4</title>
<path fill="#39e581" stroke="black" d="M105,-147.5C105,-147.5 12,-147.5 12,-147.5 6,-147.5 0,-141.5 0,-135.5 0,-135.5 0,-106.5 0,-106.5 0,-100.5 6,-94.5 12,-94.5 12,-94.5 105,-94.5 105,-94.5 111,-94.5 117,-100.5 117,-106.5 117,-106.5 117,-135.5 117,-135.5 117,-141.5 111,-147.5 105,-147.5"></path>
<text text-anchor="start" x="18.5" y="-132.3" font-family="Helvetica,sans-Serif" font-size="14.00">entropy = 0.0</text>
<text text-anchor="start" x="17.5" y="-117.3" font-family="Helvetica,sans-Serif" font-size="14.00">samples = 32</text>
<text text-anchor="start" x="8" y="-102.3" font-family="Helvetica,sans-Serif" font-size="14.00">value = [0, 32, 0]</text>
</g>
<!-- 3&#45;&gt;4 -->
<g id="edge4" class="edge">
<title>3-&gt;4</title>
<path fill="none" stroke="black" d="M147.37,-188.99C132.43,-177.73 115.54,-165 100.52,-153.68"></path>
<polygon fill="black" stroke="black" points="102.49,-150.78 92.4,-147.56 98.28,-156.37 102.49,-150.78"></polygon>
</g>
<!-- 5 -->
<g id="node6" class="node">
<title>5</title>
<path fill="#ab7bee" stroke="black" d="M234,-153C234,-153 147,-153 147,-153 141,-153 135,-147 135,-141 135,-141 135,-101 135,-101 135,-95 141,-89 147,-89 147,-89 234,-89 234,-89 240,-89 246,-95 246,-101 246,-101 246,-141 246,-141 246,-147 240,-153 234,-153"></path>
<text text-anchor="start" x="165" y="-138.8" font-family="Helvetica,sans-Serif" font-size="14.00">X</text>
<text text-anchor="start" x="175" y="-138.8" font-family="Helvetica,sans-Serif" baseline-shift="sub" font-size="14.00">1</text>
<text text-anchor="start" x="182" y="-138.8" font-family="Helvetica,sans-Serif" font-size="14.00"> ≤ 3.1</text>
<text text-anchor="start" x="143" y="-124.8" font-family="Helvetica,sans-Serif" font-size="14.00">entropy = 0.811</text>
<text text-anchor="start" x="153" y="-110.8" font-family="Helvetica,sans-Serif" font-size="14.00">samples = 4</text>
<text text-anchor="start" x="143.5" y="-96.8" font-family="Helvetica,sans-Serif" font-size="14.00">value = [0, 1, 3]</text>
</g>
<!-- 3&#45;&gt;5 -->
<g id="edge5" class="edge">
<title>3-&gt;5</title>
<path fill="none" stroke="black" d="M189.13,-188.99C189.3,-180.86 189.48,-171.96 189.66,-163.38"></path>
<polygon fill="black" stroke="black" points="193.16,-163.21 189.86,-153.14 186.16,-163.07 193.16,-163.21"></polygon>
</g>
<!-- 6 -->
<g id="node7" class="node">
<title>6</title>
<path fill="#8139e5" stroke="black" d="M106.5,-53C106.5,-53 20.5,-53 20.5,-53 14.5,-53 8.5,-47 8.5,-41 8.5,-41 8.5,-12 8.5,-12 8.5,-6 14.5,0 20.5,0 20.5,0 106.5,0 106.5,0 112.5,0 118.5,-6 118.5,-12 118.5,-12 118.5,-41 118.5,-41 118.5,-47 112.5,-53 106.5,-53"></path>
<text text-anchor="start" x="23.5" y="-37.8" font-family="Helvetica,sans-Serif" font-size="14.00">entropy = 0.0</text>
<text text-anchor="start" x="26" y="-22.8" font-family="Helvetica,sans-Serif" font-size="14.00">samples = 3</text>
<text text-anchor="start" x="16.5" y="-7.8" font-family="Helvetica,sans-Serif" font-size="14.00">value = [0, 0, 3]</text>
</g>
<!-- 5&#45;&gt;6 -->
<g id="edge6" class="edge">
<title>5-&gt;6</title>
<path fill="none" stroke="black" d="M147.86,-88.94C134.73,-79.38 120.27,-68.85 107.09,-59.25"></path>
<polygon fill="black" stroke="black" points="108.78,-56.15 98.64,-53.09 104.66,-61.81 108.78,-56.15"></polygon>
</g>
<!-- 7 -->
<g id="node8" class="node">
<title>7</title>
<path fill="#39e581" stroke="black" d="M234.5,-53C234.5,-53 148.5,-53 148.5,-53 142.5,-53 136.5,-47 136.5,-41 136.5,-41 136.5,-12 136.5,-12 136.5,-6 142.5,0 148.5,0 148.5,0 234.5,0 234.5,0 240.5,0 246.5,-6 246.5,-12 246.5,-12 246.5,-41 246.5,-41 246.5,-47 240.5,-53 234.5,-53"></path>
<text text-anchor="start" x="151.5" y="-37.8" font-family="Helvetica,sans-Serif" font-size="14.00">entropy = 0.0</text>
<text text-anchor="start" x="154" y="-22.8" font-family="Helvetica,sans-Serif" font-size="14.00">samples = 1</text>
<text text-anchor="start" x="144.5" y="-7.8" font-family="Helvetica,sans-Serif" font-size="14.00">value = [0, 1, 0]</text>
</g>
<!-- 5&#45;&gt;7 -->
<g id="edge7" class="edge">
<title>5-&gt;7</title>
<path fill="none" stroke="black" d="M190.84,-88.94C190.93,-80.66 191.02,-71.64 191.11,-63.13"></path>
<polygon fill="black" stroke="black" points="194.61,-63.13 191.22,-53.09 187.62,-63.05 194.61,-63.13"></polygon>
</g>
<!-- 9 -->
<g id="node10" class="node">
<title>9</title>
<path fill="#ab7bee" stroke="black" d="M366,-153C366,-153 279,-153 279,-153 273,-153 267,-147 267,-141 267,-141 267,-101 267,-101 267,-95 273,-89 279,-89 279,-89 366,-89 366,-89 372,-89 378,-95 378,-101 378,-101 378,-141 378,-141 378,-147 372,-153 366,-153"></path>
<text text-anchor="start" x="293" y="-138.8" font-family="Helvetica,sans-Serif" font-size="14.00">X</text>
<text text-anchor="start" x="303" y="-138.8" font-family="Helvetica,sans-Serif" baseline-shift="sub" font-size="14.00">3</text>
<text text-anchor="start" x="310" y="-138.8" font-family="Helvetica,sans-Serif" font-size="14.00"> ≤ 1.65</text>
<text text-anchor="start" x="275" y="-124.8" font-family="Helvetica,sans-Serif" font-size="14.00">entropy = 0.811</text>
<text text-anchor="start" x="285" y="-110.8" font-family="Helvetica,sans-Serif" font-size="14.00">samples = 4</text>
<text text-anchor="start" x="275.5" y="-96.8" font-family="Helvetica,sans-Serif" font-size="14.00">value = [0, 1, 3]</text>
</g>
<!-- 8&#45;&gt;9 -->
<g id="edge9" class="edge">
<title>8-&gt;9</title>
<path fill="none" stroke="black" d="M323.18,-188.99C323.1,-180.86 323.01,-171.96 322.92,-163.38"></path>
<polygon fill="black" stroke="black" points="326.42,-163.11 322.82,-153.14 319.42,-163.18 326.42,-163.11"></polygon>
</g>
<!-- 12 -->
<g id="node13" class="node">
<title>12</title>
<path fill="#8139e5" stroke="black" d="M501,-147.5C501,-147.5 408,-147.5 408,-147.5 402,-147.5 396,-141.5 396,-135.5 396,-135.5 396,-106.5 396,-106.5 396,-100.5 402,-94.5 408,-94.5 408,-94.5 501,-94.5 501,-94.5 507,-94.5 513,-100.5 513,-106.5 513,-106.5 513,-135.5 513,-135.5 513,-141.5 507,-147.5 501,-147.5"></path>
<text text-anchor="start" x="414.5" y="-132.3" font-family="Helvetica,sans-Serif" font-size="14.00">entropy = 0.0</text>
<text text-anchor="start" x="413.5" y="-117.3" font-family="Helvetica,sans-Serif" font-size="14.00">samples = 35</text>
<text text-anchor="start" x="404" y="-102.3" font-family="Helvetica,sans-Serif" font-size="14.00">value = [0, 0, 35]</text>
</g>
<!-- 8&#45;&gt;12 -->
<g id="edge12" class="edge">
<title>8-&gt;12</title>
<path fill="none" stroke="black" d="M364.95,-188.99C380,-177.73 397.02,-165 412.15,-153.68"></path>
<polygon fill="black" stroke="black" points="414.43,-156.35 420.34,-147.56 410.23,-150.74 414.43,-156.35"></polygon>
</g>
<!-- 10 -->
<g id="node11" class="node">
<title>10</title>
<path fill="#8139e5" stroke="black" d="M364.5,-53C364.5,-53 278.5,-53 278.5,-53 272.5,-53 266.5,-47 266.5,-41 266.5,-41 266.5,-12 266.5,-12 266.5,-6 272.5,0 278.5,0 278.5,0 364.5,0 364.5,0 370.5,0 376.5,-6 376.5,-12 376.5,-12 376.5,-41 376.5,-41 376.5,-47 370.5,-53 364.5,-53"></path>
<text text-anchor="start" x="281.5" y="-37.8" font-family="Helvetica,sans-Serif" font-size="14.00">entropy = 0.0</text>
<text text-anchor="start" x="284" y="-22.8" font-family="Helvetica,sans-Serif" font-size="14.00">samples = 3</text>
<text text-anchor="start" x="274.5" y="-7.8" font-family="Helvetica,sans-Serif" font-size="14.00">value = [0, 0, 3]</text>
</g>
<!-- 9&#45;&gt;10 -->
<g id="edge10" class="edge">
<title>9-&gt;10</title>
<path fill="none" stroke="black" d="M322.16,-88.94C322.07,-80.66 321.98,-71.64 321.89,-63.13"></path>
<polygon fill="black" stroke="black" points="325.38,-63.05 321.78,-53.09 318.39,-63.13 325.38,-63.05"></polygon>
</g>
<!-- 11 -->
<g id="node12" class="node">
<title>11</title>
<path fill="#39e581" stroke="black" d="M492.5,-53C492.5,-53 406.5,-53 406.5,-53 400.5,-53 394.5,-47 394.5,-41 394.5,-41 394.5,-12 394.5,-12 394.5,-6 400.5,0 406.5,0 406.5,0 492.5,0 492.5,0 498.5,0 504.5,-6 504.5,-12 504.5,-12 504.5,-41 504.5,-41 504.5,-47 498.5,-53 492.5,-53"></path>
<text text-anchor="start" x="409.5" y="-37.8" font-family="Helvetica,sans-Serif" font-size="14.00">entropy = 0.0</text>
<text text-anchor="start" x="412" y="-22.8" font-family="Helvetica,sans-Serif" font-size="14.00">samples = 1</text>
<text text-anchor="start" x="402.5" y="-7.8" font-family="Helvetica,sans-Serif" font-size="14.00">value = [0, 1, 0]</text>
</g>
<!-- 9&#45;&gt;11 -->
<g id="edge11" class="edge">
<title>9-&gt;11</title>
<path fill="none" stroke="black" d="M365.14,-88.94C378.27,-79.38 392.73,-68.85 405.91,-59.25"></path>
<polygon fill="black" stroke="black" points="408.34,-61.81 414.36,-53.09 404.22,-56.15 408.34,-61.81"></polygon>
</g>
</g>
</svg>

</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here's the training score which indeed shows the tree is perfect at classfying the flowers on the training set. This tends to result in overfitting to the training set.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>1.0</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This is an easy dataset to classify, so the overfitting is not evident here.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>0.9736842105263158</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There are 7 leaves in our tree. Note that the leaves do not have to be depicted at the bottom of the tree in the diagram. A leaf is just a node without any children and could be represented near the top of the tree.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">clf</span><span class="o">.</span><span class="n">get_n_leaves</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>7</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Inference">
<a class="anchor" href="#Inference" aria-hidden="true"><span class="octicon octicon-link"></span></a>Inference<a class="anchor-link" href="#Inference"> </a>
</h2>
<p>Now that we have trained our model, we can perform inference.</p>
<p>When inference on new samples is performed, the sample simply is examined with the "rules" created by the feature splits. Starting from the topmost node (the root node) in our example above, if feature three has a value of less than or equal 0.8, go to the left child node; otherwise go to the right. This process continues all the way down until the sample is put into a leaf.</p>
<p>The predicted class is the class in the leaf with the highest probability of that class for that leaf. In other words, simply break down the training samples by class within that leaf and choose the class with the most number of train samples. The probability of choosing that class is simply the number of training samples in that leaf belonging to that class divided by the total number of training samples in that leaf.</p>
<p>Since all of our leafs are pure, the classifier will always give 100% for its predictions. We'll rexamine this when we have impure leafs below.</p>
<p>Here are the features for the first test sample.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_test</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([5.8, 2.8, 5.1, 2.4])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The path for this sample follows down the right side of the tree. Note that features are zero-indexed.</p>
<p>Root node: Is 2.4 &lt;= 0.8? No, so go right.</p>
<p>Is 5.1 &lt;= 4.95? No, so go right.</p>
<p>Is 5.1 &lt;= 5.05? No, so go right.</p>
<p>That brings it to the leaf on the right with 35 samples, where the 3rd class (index 2) is predicted:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">([</span><span class="n">X_test</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([2])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Again, the probability is 100% since there are no training samples in that leaf from the other two classes. In the plot the node is colored dark purple. For this tree purple represents the 3rd class and the darker the shade the more probable it is.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">([</span><span class="n">X_test</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([[0., 0., 1.]])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Pruning">
<a class="anchor" href="#Pruning" aria-hidden="true"><span class="octicon octicon-link"></span></a>Pruning<a class="anchor-link" href="#Pruning"> </a>
</h2>
<p>One way to prevent overfitting is the pre-prune the tree by specifying the maximum depth and/or maximum number of leaves. Here we set the maximum depth to 3.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">clf</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s2">"entropy"</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">clf</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_svg output_subarea output_execute_result">
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
&lt;!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"&gt;
<!-- Generated by graphviz version 2.44.0 (0)
 -->
<!-- Title: Tree Pages: 1 -->
<svg width="521pt" height="361pt" viewbox="0.00 0.00 521.00 361.00" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 357)">
<title>Tree</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-357 517,-357 517,4 -4,4"></polygon>
<!-- 0 -->
<g id="node1" class="node">
<title>0</title>
<path fill="#f8f4fe" stroke="black" d="M240.5,-353C240.5,-353 132.5,-353 132.5,-353 126.5,-353 120.5,-347 120.5,-341 120.5,-341 120.5,-301 120.5,-301 120.5,-295 126.5,-289 132.5,-289 132.5,-289 240.5,-289 240.5,-289 246.5,-289 252.5,-295 252.5,-301 252.5,-301 252.5,-341 252.5,-341 252.5,-347 246.5,-353 240.5,-353"></path>
<text text-anchor="start" x="161" y="-338.8" font-family="Helvetica,sans-Serif" font-size="14.00">X</text>
<text text-anchor="start" x="171" y="-338.8" font-family="Helvetica,sans-Serif" baseline-shift="sub" font-size="14.00">3</text>
<text text-anchor="start" x="178" y="-338.8" font-family="Helvetica,sans-Serif" font-size="14.00"> ≤ 0.8</text>
<text text-anchor="start" x="139" y="-324.8" font-family="Helvetica,sans-Serif" font-size="14.00">entropy = 1.581</text>
<text text-anchor="start" x="141.5" y="-310.8" font-family="Helvetica,sans-Serif" font-size="14.00">samples = 112</text>
<text text-anchor="start" x="128.5" y="-296.8" font-family="Helvetica,sans-Serif" font-size="14.00">value = [37, 34, 41]</text>
</g>
<!-- 1 -->
<g id="node2" class="node">
<title>1</title>
<path fill="#e58139" stroke="black" d="M164,-247.5C164,-247.5 71,-247.5 71,-247.5 65,-247.5 59,-241.5 59,-235.5 59,-235.5 59,-206.5 59,-206.5 59,-200.5 65,-194.5 71,-194.5 71,-194.5 164,-194.5 164,-194.5 170,-194.5 176,-200.5 176,-206.5 176,-206.5 176,-235.5 176,-235.5 176,-241.5 170,-247.5 164,-247.5"></path>
<text text-anchor="start" x="77.5" y="-232.3" font-family="Helvetica,sans-Serif" font-size="14.00">entropy = 0.0</text>
<text text-anchor="start" x="76.5" y="-217.3" font-family="Helvetica,sans-Serif" font-size="14.00">samples = 37</text>
<text text-anchor="start" x="67" y="-202.3" font-family="Helvetica,sans-Serif" font-size="14.00">value = [37, 0, 0]</text>
</g>
<!-- 0&#45;&gt;1 -->
<g id="edge1" class="edge">
<title>0-&gt;1</title>
<path fill="none" stroke="black" d="M164.67,-288.99C157.25,-278.46 148.93,-266.64 141.37,-255.9"></path>
<polygon fill="black" stroke="black" points="144.11,-253.72 135.49,-247.56 138.39,-257.75 144.11,-253.72"></polygon>
<text text-anchor="middle" x="131.22" y="-268.49" font-family="Helvetica,sans-Serif" font-size="14.00">True</text>
</g>
<!-- 2 -->
<g id="node3" class="node">
<title>2</title>
<path fill="#e9ddfb" stroke="black" d="M307,-253C307,-253 206,-253 206,-253 200,-253 194,-247 194,-241 194,-241 194,-201 194,-201 194,-195 200,-189 206,-189 206,-189 307,-189 307,-189 313,-189 319,-195 319,-201 319,-201 319,-241 319,-241 319,-247 313,-253 307,-253"></path>
<text text-anchor="start" x="227" y="-238.8" font-family="Helvetica,sans-Serif" font-size="14.00">X</text>
<text text-anchor="start" x="237" y="-238.8" font-family="Helvetica,sans-Serif" baseline-shift="sub" font-size="14.00">2</text>
<text text-anchor="start" x="244" y="-238.8" font-family="Helvetica,sans-Serif" font-size="14.00"> ≤ 4.95</text>
<text text-anchor="start" x="209" y="-224.8" font-family="Helvetica,sans-Serif" font-size="14.00">entropy = 0.994</text>
<text text-anchor="start" x="215.5" y="-210.8" font-family="Helvetica,sans-Serif" font-size="14.00">samples = 75</text>
<text text-anchor="start" x="202" y="-196.8" font-family="Helvetica,sans-Serif" font-size="14.00">value = [0, 34, 41]</text>
</g>
<!-- 0&#45;&gt;2 -->
<g id="edge2" class="edge">
<title>0-&gt;2</title>
<path fill="none" stroke="black" d="M208.65,-288.99C214.9,-280.23 221.8,-270.58 228.35,-261.4"></path>
<polygon fill="black" stroke="black" points="231.29,-263.31 234.26,-253.14 225.59,-259.25 231.29,-263.31"></polygon>
<text text-anchor="middle" x="238.37" y="-274.1" font-family="Helvetica,sans-Serif" font-size="14.00">False</text>
</g>
<!-- 3 -->
<g id="node4" class="node">
<title>3</title>
<path fill="#4be78c" stroke="black" d="M235,-153C235,-153 142,-153 142,-153 136,-153 130,-147 130,-141 130,-141 130,-101 130,-101 130,-95 136,-89 142,-89 142,-89 235,-89 235,-89 241,-89 247,-95 247,-101 247,-101 247,-141 247,-141 247,-147 241,-153 235,-153"></path>
<text text-anchor="start" x="159" y="-138.8" font-family="Helvetica,sans-Serif" font-size="14.00">X</text>
<text text-anchor="start" x="169" y="-138.8" font-family="Helvetica,sans-Serif" baseline-shift="sub" font-size="14.00">3</text>
<text text-anchor="start" x="176" y="-138.8" font-family="Helvetica,sans-Serif" font-size="14.00"> ≤ 1.65</text>
<text text-anchor="start" x="141" y="-124.8" font-family="Helvetica,sans-Serif" font-size="14.00">entropy = 0.414</text>
<text text-anchor="start" x="147.5" y="-110.8" font-family="Helvetica,sans-Serif" font-size="14.00">samples = 36</text>
<text text-anchor="start" x="138" y="-96.8" font-family="Helvetica,sans-Serif" font-size="14.00">value = [0, 33, 3]</text>
</g>
<!-- 2&#45;&gt;3 -->
<g id="edge3" class="edge">
<title>2-&gt;3</title>
<path fill="none" stroke="black" d="M234.98,-188.99C228.91,-180.23 222.21,-170.58 215.84,-161.4"></path>
<polygon fill="black" stroke="black" points="218.69,-159.36 210.11,-153.14 212.93,-163.35 218.69,-159.36"></polygon>
</g>
<!-- 6 -->
<g id="node7" class="node">
<title>6</title>
<path fill="#843ee6" stroke="black" d="M370,-153C370,-153 277,-153 277,-153 271,-153 265,-147 265,-141 265,-141 265,-101 265,-101 265,-95 271,-89 277,-89 277,-89 370,-89 370,-89 376,-89 382,-95 382,-101 382,-101 382,-141 382,-141 382,-147 376,-153 370,-153"></path>
<text text-anchor="start" x="294" y="-138.8" font-family="Helvetica,sans-Serif" font-size="14.00">X</text>
<text text-anchor="start" x="304" y="-138.8" font-family="Helvetica,sans-Serif" baseline-shift="sub" font-size="14.00">2</text>
<text text-anchor="start" x="311" y="-138.8" font-family="Helvetica,sans-Serif" font-size="14.00"> ≤ 5.05</text>
<text text-anchor="start" x="276" y="-124.8" font-family="Helvetica,sans-Serif" font-size="14.00">entropy = 0.172</text>
<text text-anchor="start" x="282.5" y="-110.8" font-family="Helvetica,sans-Serif" font-size="14.00">samples = 39</text>
<text text-anchor="start" x="273" y="-96.8" font-family="Helvetica,sans-Serif" font-size="14.00">value = [0, 1, 38]</text>
</g>
<!-- 2&#45;&gt;6 -->
<g id="edge6" class="edge">
<title>2-&gt;6</title>
<path fill="none" stroke="black" d="M277.7,-188.99C283.69,-180.23 290.28,-170.58 296.56,-161.4"></path>
<polygon fill="black" stroke="black" points="299.45,-163.37 302.21,-153.14 293.68,-159.42 299.45,-163.37"></polygon>
</g>
<!-- 4 -->
<g id="node5" class="node">
<title>4</title>
<path fill="#39e581" stroke="black" d="M105,-53C105,-53 12,-53 12,-53 6,-53 0,-47 0,-41 0,-41 0,-12 0,-12 0,-6 6,0 12,0 12,0 105,0 105,0 111,0 117,-6 117,-12 117,-12 117,-41 117,-41 117,-47 111,-53 105,-53"></path>
<text text-anchor="start" x="18.5" y="-37.8" font-family="Helvetica,sans-Serif" font-size="14.00">entropy = 0.0</text>
<text text-anchor="start" x="17.5" y="-22.8" font-family="Helvetica,sans-Serif" font-size="14.00">samples = 32</text>
<text text-anchor="start" x="8" y="-7.8" font-family="Helvetica,sans-Serif" font-size="14.00">value = [0, 32, 0]</text>
</g>
<!-- 3&#45;&gt;4 -->
<g id="edge4" class="edge">
<title>3-&gt;4</title>
<path fill="none" stroke="black" d="M144.85,-88.94C131.29,-79.29 116.33,-68.65 102.73,-58.97"></path>
<polygon fill="black" stroke="black" points="104.64,-56.04 94.47,-53.09 100.58,-61.74 104.64,-56.04"></polygon>
</g>
<!-- 5 -->
<g id="node6" class="node">
<title>5</title>
<path fill="#ab7bee" stroke="black" d="M234,-53C234,-53 147,-53 147,-53 141,-53 135,-47 135,-41 135,-41 135,-12 135,-12 135,-6 141,0 147,0 147,0 234,0 234,0 240,0 246,-6 246,-12 246,-12 246,-41 246,-41 246,-47 240,-53 234,-53"></path>
<text text-anchor="start" x="143" y="-37.8" font-family="Helvetica,sans-Serif" font-size="14.00">entropy = 0.811</text>
<text text-anchor="start" x="153" y="-22.8" font-family="Helvetica,sans-Serif" font-size="14.00">samples = 4</text>
<text text-anchor="start" x="143.5" y="-7.8" font-family="Helvetica,sans-Serif" font-size="14.00">value = [0, 1, 3]</text>
</g>
<!-- 3&#45;&gt;5 -->
<g id="edge5" class="edge">
<title>3-&gt;5</title>
<path fill="none" stroke="black" d="M189.17,-88.94C189.35,-80.66 189.55,-71.64 189.73,-63.13"></path>
<polygon fill="black" stroke="black" points="193.23,-63.16 189.95,-53.09 186.23,-63.01 193.23,-63.16"></polygon>
</g>
<!-- 7 -->
<g id="node8" class="node">
<title>7</title>
<path fill="#ab7bee" stroke="black" d="M366,-53C366,-53 279,-53 279,-53 273,-53 267,-47 267,-41 267,-41 267,-12 267,-12 267,-6 273,0 279,0 279,0 366,0 366,0 372,0 378,-6 378,-12 378,-12 378,-41 378,-41 378,-47 372,-53 366,-53"></path>
<text text-anchor="start" x="275" y="-37.8" font-family="Helvetica,sans-Serif" font-size="14.00">entropy = 0.811</text>
<text text-anchor="start" x="285" y="-22.8" font-family="Helvetica,sans-Serif" font-size="14.00">samples = 4</text>
<text text-anchor="start" x="275.5" y="-7.8" font-family="Helvetica,sans-Serif" font-size="14.00">value = [0, 1, 3]</text>
</g>
<!-- 6&#45;&gt;7 -->
<g id="edge7" class="edge">
<title>6-&gt;7</title>
<path fill="none" stroke="black" d="M323.16,-88.94C323.07,-80.66 322.98,-71.64 322.89,-63.13"></path>
<polygon fill="black" stroke="black" points="326.38,-63.05 322.78,-53.09 319.39,-63.13 326.38,-63.05"></polygon>
</g>
<!-- 8 -->
<g id="node9" class="node">
<title>8</title>
<path fill="#8139e5" stroke="black" d="M501,-53C501,-53 408,-53 408,-53 402,-53 396,-47 396,-41 396,-41 396,-12 396,-12 396,-6 402,0 408,0 408,0 501,0 501,0 507,0 513,-6 513,-12 513,-12 513,-41 513,-41 513,-47 507,-53 501,-53"></path>
<text text-anchor="start" x="414.5" y="-37.8" font-family="Helvetica,sans-Serif" font-size="14.00">entropy = 0.0</text>
<text text-anchor="start" x="413.5" y="-22.8" font-family="Helvetica,sans-Serif" font-size="14.00">samples = 35</text>
<text text-anchor="start" x="404" y="-7.8" font-family="Helvetica,sans-Serif" font-size="14.00">value = [0, 0, 35]</text>
</g>
<!-- 6&#45;&gt;8 -->
<g id="edge8" class="edge">
<title>6-&gt;8</title>
<path fill="none" stroke="black" d="M367.49,-88.94C381.15,-79.29 396.22,-68.65 409.93,-58.97"></path>
<polygon fill="black" stroke="black" points="412.11,-61.72 418.26,-53.09 408.07,-56 412.11,-61.72"></polygon>
</g>
</g>
</svg>

</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>0.9821428571428571</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>0.9736842105263158</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here is a sample where we are only 75% sure that it is class 2, since only 3 of the 4 samples in its leaf are class 2.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">([</span><span class="n">X_test</span><span class="p">[</span><span class="mi">20</span><span class="p">]])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([2])</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">([</span><span class="n">X_test</span><span class="p">[</span><span class="mi">20</span><span class="p">]])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([[0.  , 0.25, 0.75]])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>A popular and effective way to reduce overfitting is to create a "forest" of weak decision trees and use them together (for example, random forests). This is beyond the scope of this notebook.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Information-gain-&amp;-splits">
<a class="anchor" href="#Information-gain-&amp;-splits" aria-hidden="true"><span class="octicon octicon-link"></span></a>Information gain &amp; splits<a class="anchor-link" href="#Information-gain-&amp;-splits"> </a>
</h2>
<p>Let's talk a little bit more about how trees use entropy (or alternatively Gini) to determine splits.</p>
<p>Information gain is calculated by cycling through all possible splits in the training set. Practically this is the process:</p>
<ol>
<li>Select the first feature.</li>
<li>Pick the halfway point between the first sample and the second sample.</li>
<li>Calculate the entropy of the two child nodes if a split is made at that point.</li>
<li>Repeat steps 2 and 3 for all midpoints for this feature.</li>
<li>Go back to step 1 and repeat for all features.</li>
</ol>
<p>At the end, pick the feature and split that has the lowest weighted summation of the entropies for the two child nodes.</p>
<p>Again, information gain is the difference in entropy of the parent node and the weighted summation of entropies of the two child nodes. Since the entropy of the parent node is the same for each potential split that we try, we only need to calculate the entropies of the child nodes for a split and find the split that minimizes their weighted sum since that will maximize the information gained.</p>
<p>Here's the formula for information gain (IG), where $H_{parent}$ is the entropy of the parent node, $N_{left}$ is the number of samples in the left child, $H_{left}$ is the entropy of the left child, $N_{right}$ is the number of samples in the right child, $H_{right}$ is the entropy of the right child:</p>
<p>$IG = H_{parent} - (N_{left} H_{left} + N_{right} H_{right})$</p>
<p>Here's a tree with a max depth of 1 using entropy to split:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">clf</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s2">"entropy"</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">clf</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_svg output_subarea output_execute_result">
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
&lt;!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"&gt;
<!-- Generated by graphviz version 2.44.0 (0)
 -->
<!-- Title: Tree Pages: 1 -->
<svg width="268pt" height="161pt" viewbox="0.00 0.00 268.00 161.00" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 157)">
<title>Tree</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-157 264,-157 264,4 -4,4"></polygon>
<!-- 0 -->
<g id="node1" class="node">
<title>0</title>
<path fill="#f8f4fe" stroke="black" d="M181.5,-153C181.5,-153 73.5,-153 73.5,-153 67.5,-153 61.5,-147 61.5,-141 61.5,-141 61.5,-101 61.5,-101 61.5,-95 67.5,-89 73.5,-89 73.5,-89 181.5,-89 181.5,-89 187.5,-89 193.5,-95 193.5,-101 193.5,-101 193.5,-141 193.5,-141 193.5,-147 187.5,-153 181.5,-153"></path>
<text text-anchor="start" x="98" y="-138.8" font-family="Helvetica,sans-Serif" font-size="14.00">X</text>
<text text-anchor="start" x="108" y="-138.8" font-family="Helvetica,sans-Serif" baseline-shift="sub" font-size="14.00">2</text>
<text text-anchor="start" x="115" y="-138.8" font-family="Helvetica,sans-Serif" font-size="14.00"> ≤ 2.35</text>
<text text-anchor="start" x="80" y="-124.8" font-family="Helvetica,sans-Serif" font-size="14.00">entropy = 1.581</text>
<text text-anchor="start" x="82.5" y="-110.8" font-family="Helvetica,sans-Serif" font-size="14.00">samples = 112</text>
<text text-anchor="start" x="69.5" y="-96.8" font-family="Helvetica,sans-Serif" font-size="14.00">value = [37, 34, 41]</text>
</g>
<!-- 1 -->
<g id="node2" class="node">
<title>1</title>
<path fill="#e58139" stroke="black" d="M105,-53C105,-53 12,-53 12,-53 6,-53 0,-47 0,-41 0,-41 0,-12 0,-12 0,-6 6,0 12,0 12,0 105,0 105,0 111,0 117,-6 117,-12 117,-12 117,-41 117,-41 117,-47 111,-53 105,-53"></path>
<text text-anchor="start" x="18.5" y="-37.8" font-family="Helvetica,sans-Serif" font-size="14.00">entropy = 0.0</text>
<text text-anchor="start" x="17.5" y="-22.8" font-family="Helvetica,sans-Serif" font-size="14.00">samples = 37</text>
<text text-anchor="start" x="8" y="-7.8" font-family="Helvetica,sans-Serif" font-size="14.00">value = [37, 0, 0]</text>
</g>
<!-- 0&#45;&gt;1 -->
<g id="edge1" class="edge">
<title>0-&gt;1</title>
<path fill="none" stroke="black" d="M104.33,-88.94C97.68,-80.02 90.39,-70.25 83.62,-61.18"></path>
<polygon fill="black" stroke="black" points="86.37,-59.01 77.59,-53.09 80.76,-63.2 86.37,-59.01"></polygon>
<text text-anchor="middle" x="73.99" y="-74.13" font-family="Helvetica,sans-Serif" font-size="14.00">True</text>
</g>
<!-- 2 -->
<g id="node3" class="node">
<title>2</title>
<path fill="#e9ddfb" stroke="black" d="M248,-53C248,-53 147,-53 147,-53 141,-53 135,-47 135,-41 135,-41 135,-12 135,-12 135,-6 141,0 147,0 147,0 248,0 248,0 254,0 260,-6 260,-12 260,-12 260,-41 260,-41 260,-47 254,-53 248,-53"></path>
<text text-anchor="start" x="150" y="-37.8" font-family="Helvetica,sans-Serif" font-size="14.00">entropy = 0.994</text>
<text text-anchor="start" x="156.5" y="-22.8" font-family="Helvetica,sans-Serif" font-size="14.00">samples = 75</text>
<text text-anchor="start" x="143" y="-7.8" font-family="Helvetica,sans-Serif" font-size="14.00">value = [0, 34, 41]</text>
</g>
<!-- 0&#45;&gt;2 -->
<g id="edge2" class="edge">
<title>0-&gt;2</title>
<path fill="none" stroke="black" d="M151,-88.94C157.75,-80.02 165.15,-70.25 172.01,-61.18"></path>
<polygon fill="black" stroke="black" points="174.89,-63.18 178.13,-53.09 169.31,-58.95 174.89,-63.18"></polygon>
<text text-anchor="middle" x="181.56" y="-74.15" font-family="Helvetica,sans-Serif" font-size="14.00">False</text>
</g>
</g>
</svg>

</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's implement our entropy calculation. As a reminder, the formula is:</p>
<p>$H(p) = -\sum_{i=1}^{J}p_{i}\log_{2}(p_{i})$</p>
<p>This takes a list of targets and calculates the entropy for that node.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>

<span class="k">def</span> <span class="nf">entropy</span><span class="p">(</span><span class="n">values</span><span class="p">):</span>
    <span class="n">total</span> <span class="o">=</span> <span class="n">values</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">total</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>
    
    <span class="n">s</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">c</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">x</span><span class="o">/</span><span class="n">total</span>
        <span class="n">s</span> <span class="o">+=</span> <span class="n">p</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
        
    <span class="k">return</span> <span class="o">-</span><span class="n">s</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Plotting-entropy-in-the-binary-class-case">
<a class="anchor" href="#Plotting-entropy-in-the-binary-class-case" aria-hidden="true"><span class="octicon octicon-link"></span></a>Plotting entropy in the binary class case<a class="anchor-link" href="#Plotting-entropy-in-the-binary-class-case"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's take a quick look at an example where we have two classes, 0 and 1, in 100 samples (so 50 of each class) to get an idea of what entropy is describing. If we perfectly split our data into 0's in the left bucket, and 1's into the right bucket, we have 0 entropy. Whatever (hypothetical) decision rule that caused that split has split our data perfectly.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">left</span><span class="p">,</span> <span class="n">right</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">50</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Because each node is pure, the entropy is 0 for each node:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">entropy</span><span class="p">(</span><span class="n">left</span><span class="p">),</span> <span class="n">entropy</span><span class="p">(</span><span class="n">right</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(-0.0, -0.0)</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">left</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">right</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now let's change 1 sample - moving one of the 0's from the left node to the right, and one of the 1's from the right node to the left. Here are the entropies of those child nodes. In both cases, the entropy goes up by the same amount.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">entropy</span><span class="p">(</span><span class="n">left</span><span class="p">),</span> <span class="n">entropy</span><span class="p">(</span><span class="n">right</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(0.14144054254182067, 0.14144054254182067)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's make this discussion even simpler by looking at just a single node containing 100 samples of either 0's or 1's. Let's start with a pure node of containing just 0's and incrementally change those 0's to 1's and find out what happens with the entropy:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">node</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">99</span><span class="p">):</span>
    <span class="n">x</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="mf">100.</span><span class="p">)</span>
    <span class="n">node</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">y</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">entropy</span><span class="p">(</span><span class="n">node</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here's the plot of the entropy of that node as a function of the fraction of positive class samples (1's) in that node. Initially when the fraction is zero (the node is all 0's), the node is pure, so the entropy is 0. As we begin to change 0's for 1's the entropy increases and eventually reaches 1 when the fraction is 0.5 (equal amount of 1's and 0's). From there, the entropy decreases as the fraction of the positive class continues to increase and eventually reaches zero again when the node is all 1's and is thu pure.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">"Entropy"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">"Fraction positive class"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Remember, splits are determined by information gain, that is, the difference in entropy of the parent and the weighted summation of the entropies of the children. If you have a child node with an entropy of 1.0 that means that node contributes nothing to understanding of how to split the data into the two classes. If you have a child node with an entropy of 0.0 you have been able to perfectly segment out those samples. But again, we want the weighted combination of the entropies of the children to be low. You might have a situation where one is very low and one is very high, but it's better to split elsewhere to make the weighted sum lower.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Finding-the-best-split-through-iteration">
<a class="anchor" href="#Finding-the-best-split-through-iteration" aria-hidden="true"><span class="octicon octicon-link"></span></a>Finding the best split through iteration<a class="anchor-link" href="#Finding-the-best-split-through-iteration"> </a>
</h3>
<p>Here's our original list of targets from the Iris example:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y_train</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([1, 1, 2, 0, 2, 0, 0, 1, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 1, 2,
       1, 0, 2, 1, 1, 1, 1, 2, 0, 0, 2, 1, 0, 0, 1, 0, 2, 1, 0, 1, 2, 1,
       0, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 2, 2, 0, 0, 2, 0, 0, 0, 1, 2,
       2, 0, 0, 0, 1, 1, 0, 0, 1, 0, 2, 1, 2, 1, 0, 2, 0, 2, 0, 0, 2, 0,
       2, 1, 1, 1, 2, 2, 1, 1, 0, 1, 2, 2, 0, 1, 1, 1, 1, 0, 0, 0, 2, 1,
       2, 0])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here's the associated entropy which matches above. This is the entropy of the root node.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">entropy</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>1.5807197138422104</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now let's get the entropies of the child nodes for the split that was found. In this case it was feature 3 with the split at 0.8.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">feat</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">x</span> <span class="o">=</span> <span class="mf">0.8</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here are the samples that went into the left node. As you can see all of them are of class <code>0</code>. There is no entropy associated with this node - the node is pure.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">left</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="n">X_train</span><span class="p">[:,</span><span class="n">feat</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">x</span><span class="p">]</span>
<span class="n">left</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">entropy</span><span class="p">(</span><span class="n">left</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>-0.0</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here are the samples that went into the right node:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">right</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="n">X_train</span><span class="p">[:,</span><span class="n">feat</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">x</span><span class="p">]</span>
<span class="n">right</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([1, 1, 2, 2, 1, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 1, 2, 1, 2, 1,
       1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 2, 2, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1,
       2, 2, 1, 1, 1, 1, 2, 1, 2])</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">entropy</span><span class="p">(</span><span class="n">right</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>0.993707106604508</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we need the cycle through each feature, and then cycle through each possible split.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>

<span class="k">def</span> <span class="nf">calc_entropies</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    
    <span class="n">n</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">min_ents</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
    <span class="n">min_splits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">feat</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    
        <span class="c1"># Use set to remove dups; sort it to get halfway points</span>
        <span class="n">points</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="n">feat</span><span class="p">])))</span>
        
        <span class="n">splits</span> <span class="o">=</span> <span class="p">[(</span><span class="n">points</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="n">points</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">/</span><span class="mf">2.</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">points</span><span class="p">))]</span>
        <span class="n">entropies</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">splits</span><span class="p">:</span>
        
            <span class="n">l</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="n">X_train</span><span class="p">[:,</span><span class="n">feat</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">x</span><span class="p">]</span>
            <span class="n">r</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="n">X_train</span><span class="p">[:,</span><span class="n">feat</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">x</span><span class="p">]</span>
        
            <span class="n">e</span> <span class="o">=</span> <span class="p">(</span><span class="n">l</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">entropy</span><span class="p">(</span><span class="n">l</span><span class="p">)</span> <span class="o">+</span> <span class="n">r</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">entropy</span><span class="p">(</span><span class="n">r</span><span class="p">))</span> <span class="o">/</span> <span class="n">n</span>
            <span class="n">entropies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>

        <span class="n">feat_min_ent</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">entropies</span><span class="p">)</span>
        <span class="n">min_ents</span><span class="p">[</span><span class="n">feat</span><span class="p">]</span> <span class="o">=</span> <span class="n">entropies</span><span class="p">[</span><span class="n">feat_min_ent</span><span class="p">]</span>
        <span class="n">min_splits</span><span class="p">[</span><span class="n">feat</span><span class="p">]</span> <span class="o">=</span> <span class="n">splits</span><span class="p">[</span><span class="n">feat_min_ent</span><span class="p">]</span>
        
    <span class="n">min_feat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">min_ents</span><span class="p">)</span>
            
    <span class="k">return</span> <span class="n">min_feat</span><span class="p">,</span> <span class="n">min_splits</span><span class="p">[</span><span class="n">min_feat</span><span class="p">],</span> <span class="n">min_ents</span><span class="p">[</span><span class="n">min_feat</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">calc_entropies</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(2, 2.35, 0.6654288660298044)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Note that in this example splitting feature 3 at 0.8 gives the same entropy as the above split. <code>np.argmin</code> returns the argument of the first minimum in the case of a tie.</p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="wesbarnett/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/machinelearning/2019/05/14/decision-trees.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>© 2020 Wes Barnett</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/wesbarnett" title="wesbarnett"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://www.linkedin.com/in/wesbarnett" title="wesbarnett"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#linkedin"></use></svg></a></li><li><a rel="me" href="https://twitter.com/WesBarnettPhD" title="WesBarnettPhD"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
